{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for file in Path(\"data-abstract\").rglob(\"*.txt\"):\n",
    "    data.append(file.parent / file.name)\n",
    "n_files = len(data)\n",
    "data[0]\n",
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The movie has unique characteristics. When someone writes an opinion about a movie, not only the story in the movie itself is written, but also the people involved in the movie are also written. Opinion ordinary movie written in social media primarily Twitter.To get a tendency of opinion on the movie, whether an opinion is likely positive, negative or neutral, it takes a sentiment analysis. This study aims to classify the sentiment is positive, negative and neutral from opinions Indonesian language movie and look for the accuracy, precision, recall, and f-measure of the method used is Dynamic Convolutional Neural Network. The test results on a system that is built to show that Dynamic Convolutional Neural Network algorithm provides accurate results better than Naive Bayes method, the value of accuracy of 80,99%, the value of precision 81,00%, recall 81,00%, f-measure 79,00% while the value of the resulting accuracy Naive Bayes amounted to 76,21%, precision 78,00%, recall 76,00%, f-measure 75,00%.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=[]\n",
    "for txt in data:\n",
    "    with open(txt) as f:\n",
    "        txtString = f.read()\n",
    "    docs.append(txtString)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9x478 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 668 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.9, min_df=1, stop_words='english', use_idf=True, norm=None)\n",
    "transformed_documents = vectorizer.fit_transform(docs)\n",
    "transformed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.65662747,  0.        ,  0.        , ...,  0.        ,\n",
       "         2.60943791,  6.61191841],\n",
       "       [ 0.        ,  2.60943791,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transDoc = transformed_documents.toarray()\n",
    "transDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"./tdidf-output\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output=[str(txt).replace(\".txt\", \".csv\").replace(\"txt/\", \"tdidf-output/\") for txt in data]\n",
    "for counter, doc in enumerate(transDoc):\n",
    "    tfidfTuples = list(zip(vectorizer.get_feature_names(), doc))\n",
    "    oneDoc = pd.DataFrame.from_records(tfidfTuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    oneDoc.to_csv(output[counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053121</td>\n",
       "      <td>0.205699</td>\n",
       "      <td>0.095266</td>\n",
       "      <td>0.118505</td>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.113710</td>\n",
       "      <td>0.087469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.081563</td>\n",
       "      <td>0.039491</td>\n",
       "      <td>0.034899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205699</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177104</td>\n",
       "      <td>0.124945</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.180539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095266</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>0.177104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.039642</td>\n",
       "      <td>0.071319</td>\n",
       "      <td>0.070540</td>\n",
       "      <td>0.172198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118505</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.124945</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.059154</td>\n",
       "      <td>0.040180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>0.039642</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.028476</td>\n",
       "      <td>0.015648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.081563</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.071319</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.014050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.113710</td>\n",
       "      <td>0.039491</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.070540</td>\n",
       "      <td>0.059154</td>\n",
       "      <td>0.028476</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.087469</td>\n",
       "      <td>0.034899</td>\n",
       "      <td>0.180539</td>\n",
       "      <td>0.172198</td>\n",
       "      <td>0.040180</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>0.105533</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.053121  0.205699  0.095266  0.118505  0.039177  0.010320   \n",
       "1  0.053121  1.000000  0.052124  0.023823  0.048362  0.012941  0.081563   \n",
       "2  0.205699  0.052124  1.000000  0.177104  0.124945  0.056953  0.038829   \n",
       "3  0.095266  0.023823  0.177104  1.000000  0.071479  0.039642  0.071319   \n",
       "4  0.118505  0.048362  0.124945  0.071479  1.000000  0.212122  0.007631   \n",
       "5  0.039177  0.012941  0.056953  0.039642  0.212122  1.000000  0.020198   \n",
       "6  0.010320  0.081563  0.038829  0.071319  0.007631  0.020198  1.000000   \n",
       "7  0.113710  0.039491  0.067527  0.070540  0.059154  0.028476  0.001156   \n",
       "8  0.087469  0.034899  0.180539  0.172198  0.040180  0.015648  0.014050   \n",
       "\n",
       "          7         8  \n",
       "0  0.113710  0.087469  \n",
       "1  0.039491  0.034899  \n",
       "2  0.067527  0.180539  \n",
       "3  0.070540  0.172198  \n",
       "4  0.059154  0.040180  \n",
       "5  0.028476  0.015648  \n",
       "6  0.001156  0.014050  \n",
       "7  1.000000  0.105533  \n",
       "8  0.105533  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectors = [t for t in transDoc]\n",
    "con=cosine_similarity(vectors)\n",
    "conpd = pd.DataFrame(con, index=[0,1,2,3,4,5,6,7,8], columns=[0,1,2,3,4,5,6,7,8])\n",
    "conpd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
